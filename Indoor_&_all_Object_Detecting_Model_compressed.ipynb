{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkdoEs5Xa4Wf"
   },
   "source": [
    "Step 1: Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R57W_lT6RyWZ",
    "outputId": "f1a47592-660d-410e-d1d8-694a17235b29"
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics kaggle gradio -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4K6oGZBazNj"
   },
   "source": [
    "Step 2: Upload kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "Qvnh83snSErG",
    "outputId": "c7dca4bc-9fae-46a0-dae4-134380ecd55d"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otbNyw8FbhJs"
   },
   "source": [
    "Step 3: Move kaggle.json to the correct location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBTmmFCQR05t"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MreZq4gHbkuQ"
   },
   "source": [
    "Step 4: Download and unzip the indoor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZRfIYfiR6Rt",
    "outputId": "28f22148-e808-4339-cc8e-95749002f64e"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d thepbordin/indoor-object-detection\n",
    "!unzip -q indoor-object-detection.zip -d dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mp3MrcvbtCn"
   },
   "source": [
    "Step 5: Prepare indoor-data.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZOl0hL0WmpF",
    "outputId": "d8e8d59d-acd7-46de-aef9-d9887fd6d667"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Create YOLOv8 model\n",
    "model = YOLO('yolov8l.pt')\n",
    "\n",
    "yaml_content = '''\n",
    "train: ../train/images\n",
    "val: ../valid/images\n",
    "nc: 10\n",
    "names: ['door','openedDoor','cabinetDoor','refrigeratorDoor','window','chair','table','cabinet','sofa','pole']\n",
    "'''\n",
    "with open('/content/dataset/indoor-data.yaml', 'w') as f:\n",
    "    f.write(yaml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUllG9dibzhY"
   },
   "source": [
    "Step 6: Train YOLOv8n model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxoqpA1A0NOR",
    "outputId": "d13862da-0734-4c15-9eec-7d87b107025b"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8l.pt')\n",
    "\n",
    "model.train(data='/content/dataset/indoor-data.yaml', epochs=10, imgsz=640, batch=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf3j2ddXb8I-"
   },
   "source": [
    "Step 7: Evaluate on validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwUPGft6b-_B",
    "outputId": "fc109b3d-aa34-4d89-f99c-0a05e0de1dc7"
   },
   "outputs": [],
   "source": [
    "metrics = model.val()\n",
    "print(\"Validation metrics:\")\n",
    "print(metrics.results_dict.keys()) # Print the keys to inspect\n",
    "# print(f\"F1 Score: {metrics.results_dict['metrics/f1(B)']:.2f}\") # Access F1 score directly\n",
    "print(f\"Precision: {metrics.results_dict['metrics/precision(B)']:.2f}\")\n",
    "print(f\"Recall: {metrics.results_dict['metrics/recall(B)']:.2f}\")\n",
    "print(f\"mAP50: {metrics.results_dict['metrics/mAP50(B)']:.2f}\")\n",
    "print(f\"mAP50-95: {metrics.results_dict['metrics/mAP50-95(B)']:.2f}\")\n",
    "# The \"(B)\" in the metric names like \"metrics/precision(B)\" likely stands for \"Bounding Box\".\n",
    "# This indicates that the metric is calculated based on the performance of the model in predicting\n",
    "# bounding boxes around the detected objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQX0bDwdb_ks"
   },
   "source": [
    "Step 8: Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89hinpdacDMo"
   },
   "outputs": [],
   "source": [
    "model.save('yolov8l-indoor.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zox_qTr-cKkI"
   },
   "source": [
    "Step 9: Relevant Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "e8joE5AIRl38",
    "outputId": "30ae567e-4e0e-4746-b97d-3b6463013b12"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = np.random.rand(10, 12)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title(\"Heatmap\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_V0l3YSWcDhl"
   },
   "source": [
    "Step 10: Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMKqVBYMoKz7"
   },
   "source": [
    "üß† STEP 1: Upload Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "SVCnLmvdpJCw",
    "outputId": "153b12df-e96b-4990-cc45-91e36c254beb"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "\n",
    "def detect_image(img):\n",
    "    results = model(img)\n",
    "\n",
    "    # Get annotated image\n",
    "    annotated_img = results[0].plot()\n",
    "\n",
    "    # Extract list of detected object names\n",
    "    classes = results[0].names  # class_id to label map\n",
    "    detections = results[0].boxes.cls.tolist()  # list of class IDs\n",
    "    detected_objects = list(set([classes[int(cls_id)] for cls_id in detections]))\n",
    "\n",
    "    return annotated_img, \", \".join(detected_objects) if detected_objects else \"No objects detected\"\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## üß† YOLOv8 Image Detection\")\n",
    "    gr.Markdown(\"Upload an image to detect objects.\")\n",
    "\n",
    "    with gr.Tab(\"Image Detection\"):\n",
    "        with gr.Row():\n",
    "            image_input = gr.Image(type=\"pil\", label=\"Upload Image\")\n",
    "            image_output = gr.Image(type=\"pil\", label=\"Detected Image\")\n",
    "\n",
    "        with gr.Row():\n",
    "            object_list = gr.Textbox(label=\"Detected Objects\", interactive=False)\n",
    "\n",
    "        with gr.Row():\n",
    "            submit_btn = gr.Button(\"Submit\")\n",
    "\n",
    "        submit_btn.click(fn=detect_image, inputs=image_input, outputs=[image_output, object_list])\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hT3AtXzLtXzu"
   },
   "source": [
    "üìÅ STEP 2: Upload your video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f8cg6gnjk7HW",
    "outputId": "42c9f5c6-1d87-47de-ab47-39788613665c"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get uploaded file path\n",
    "video_path = list(uploaded.keys())[0]\n",
    "print(f\"Video uploaded: {video_path}\")\n",
    "\n",
    "# üèó STEP 3: Load the YOLOv8 model\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "\n",
    "# üöÄ STEP 4: Run prediction on uploaded video\n",
    "results = model.predict(source=video_path, save=True, conf=0.6)\n",
    "\n",
    "# üß≠ STEP 5: Locate output path\n",
    "import os\n",
    "\n",
    "# Get the most recent prediction folder directly from the results object\n",
    "output_folder = results[0].save_dir\n",
    "\n",
    "from IPython.display import Video, display\n",
    "\n",
    "# Find the processed video file within the output_folder\n",
    "output_files = os.listdir(output_folder)\n",
    "video_output_path = os.path.join(output_folder, [f for f in output_files if f.endswith('.mp4') or f.endswith('.avi')][0])\n",
    "\n",
    "print(f\"Output video path: {video_output_path}\")\n",
    "display(Video(video_output_path, embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bs9tzgjIt9f0"
   },
   "source": [
    "Step 11:üìÅLocate Processed Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSc93bkfk7Ek"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video, display\n",
    "\n",
    "# üîç Find the actual filename\n",
    "# Use the output_folder determined in the prediction step\n",
    "output_dir = output_folder\n",
    "all_files = os.listdir(output_dir)\n",
    "video_file = [f for f in all_files if f.endswith(\".mp4\") or f.endswith(\".avi\")][0]\n",
    "\n",
    "# ‚úÖ Safe full path\n",
    "video_path = os.path.join(output_dir, video_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcMKwFmnue4d"
   },
   "source": [
    "Step 12:üìõ Rename Output Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLGxMvEgmAhm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "old_path = os.path.join(output_dir, video_file)\n",
    "new_path = os.path.join(output_dir, \"detected_output.mp4\")\n",
    "os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ReoZum_u0Ul"
   },
   "source": [
    "Step 13:üé¨ Download the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "NYbKmIMPmAfY",
    "outputId": "3a33654b-4bd4-481b-bb6f-4fc686752129"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(new_path)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
